# -*- coding: utf-8 -*-
"""FAStats.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x87wKG0XmCV3Q4_bRoBiCVy4-fp3UQ8W
"""

import pandas
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
from statistics import mode #import necessary libraries

#read the csv dataset
df = pandas.read_csv("https://course-resources.minerva.edu/uploaded_files/mu/00331768-5264/cornerstone-metrics-data-by-class-2021-2022--sample.csv")

fa = df[df['course']=='Formal Analyses'] #dividing data into 2 sample groups: FA and MC courses
mc = df[df['course']=='Multimodal Communications']

#Calculate Descriptive Stats

fa_mean = fa['student_talk_time_percent'].mean() #calculating mean for sample Formal Analyses
fa_median = np.median(fa['student_talk_time_percent']) #calculating median for sample FA
fa_std = np.std(fa['student_talk_time_percent']) #calculating standard deviation for sample FA

mc_mean = mc['student_talk_time_percent'].mean() #calculating mean for sample Multimodal Communications
mc_median = np.median(mc['student_talk_time_percent']) #calculating median for sample MC
mc_std = np.std(mc['student_talk_time_percent']) #calculating standard deviation for sample MC


print('FA:') #displaying descriptive stats for sample FA
print('mean:', fa_mean)
print('median:',fa_median)
print('mode:', mode(fa['student_talk_time_percent'])) #finding mode
print('range:', np.ptp(fa['student_talk_time_percent'])) #finding range
print('standard deviation:', fa_std)

print('MC:') #displaying descriptive stats for sample MC
print('mean:', mc_mean)
print('median:', mc_median)
print('mode:', mode(mc['student_talk_time_percent']))
print('range:', np.ptp(mc['student_talk_time_percent']))
print('standard deviation:', mc_std)

#Data Vizualization

plt.hist(fa['student_talk_time_percent'], label='FA', bins = 10) #building first histogram with 10 bins
plt.hist(mc['student_talk_time_percent'], label='MC', alpha=.7, color = 'orange', bins = 10) #building second histogram with a different color and half-transparent
plt.title('Student Talk Time Percentage in Formal Analyses and Multimodal Communications classes') #adding title
plt.xlabel('Student Talk Time Percentage')
plt.ylabel('Frequency') #setting labels for x and y axes
plt.yticks(range(0, 25, 5)) #setting range of values for y axis
plt.axvline(fa_mean, color='black', linewidth=1) #plot a dashed line for mean
plt.axvline(mc_mean, color='black', linewidth=1)
plt.axvline(fa_median, color='navy', linestyle='dashed', linewidth=1) #plot a line for median
plt.axvline(mc_median, color='brown', linestyle='dashed', linewidth=1)
plt.legend() #adding legend

plt.text(fa_mean, plt.ylim()[1] * 0.95, ' FA Mean', color='black', ha='left') #adding text to the mean line
plt.text(mc_mean, plt.ylim()[1] * 0.9, 'MC Mean', color='black', ha='right')
plt.text(fa_median, plt.ylim()[1] * 0.85, 'FA Median ', color='navy', ha='right') #adding text to the median line
plt.text(mc_median, plt.ylim()[1] * 0.80, ' MC Median', color='brown', ha='left')

plt.show() #display the graph

#Difference of Means Test
#Statistical Significance

tails = 2 #set number of tails
n = 60 #set the sample size
df = n - 1 #set the degrees of freedom
alpha = 0.05 #set the significance level

SE = ((fa_std**2/n) + (mc_std**2/n))**0.5 #calculating standard error

t = (mc_mean - fa_mean)/SE #calculate t-score for difference of means
p = tails * stats.t.cdf(-t, df) #calculate p value

print("Standard Error = ", SE)
print("t-score = ", t)
print("p value = ", p)

#Practical significance

sdpooled = np.sqrt((mc_std**2 + fa_std**2)/2) #calculate pooled standard deviation
d = (mc_mean - fa_mean)/sdpooled #calculate Cohen's d

print("SD pooled = ", sdpooled)
print("Cohen's d = ", d)

#Statistical power

import statsmodels.stats.power as smp #import library for stat power
#calculate the power, parameters: effect size, sample size, significance level, ratio of sample size 1 to 2, two-sided test
power = smp.TTestIndPower().solve_power(effect_size = d, nobs1= n , alpha = alpha, ratio = n/n, alternative='two-sided')


print("Power = ", power)

#Confidence Intervals

conf_lvl = 0.95 #Set the confidence level
npop = 500 #Set population size

t = stats.t.ppf(1 - (1-conf_lvl)/2, df) #Gives 2.0009 t-score for 95% confidence level

fpc = np.sqrt((npop - n)/(npop - 1)) #set finite population correction factor

fa_se = fa_std/(n**0.5) * fpc#finding Standard Error for FA and MC, and applying finite population correction
mc_se = mc_std/(n**0.5) * fpc

fa_margin = t * fa_se #calculating Margin of Error for FA and MC
mc_margin = t * mc_se

fa_lowbound = fa_mean - fa_margin #calculating lower bound
fa_highbound = fa_mean + fa_margin #calculating higher bound
mc_lowbound = mc_mean - mc_margin
mc_highbound = mc_mean + mc_margin

print("FA Margin of error  = ", fa_margin )
print("FA Confidence interval = ", fa_lowbound, ", ", fa_highbound )
print("MC Margin of error  = ", mc_margin )
print("MC Confidence interval = ", mc_lowbound, ", ", mc_highbound )